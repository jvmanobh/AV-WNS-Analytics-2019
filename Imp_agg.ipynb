{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Datasets\n",
    "tr = pd.read_csv('train.csv')\n",
    "ts = pd.read_csv('test.csv')\n",
    "view = pd.read_csv('view_log.csv')\n",
    "item = pd.read_csv('item_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 237609 entries, 0 to 237608\n",
      "Data columns (total 7 columns):\n",
      "impression_id      237609 non-null object\n",
      "impression_time    237609 non-null datetime64[ns]\n",
      "user_id            237609 non-null int64\n",
      "app_code           237609 non-null int64\n",
      "os_version         237609 non-null object\n",
      "is_4G              237609 non-null int64\n",
      "is_click           237609 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Converting Impression_time field to datetime format in train and test dataset\n",
    "tr['impression_time'] = pd.to_datetime(tr.impression_time)\n",
    "ts['impression_time'] = pd.to_datetime(ts.impression_time)\n",
    "tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Objective:</font>\n",
    "> For the unique impression id in train and test dataset, get only the past user level aggreagtion data. i.e Get data from view_log dataset where server time of the view_log must be less than or equal to ad impression time.\n",
    "\n",
    "### <font color='green'>Approach:</font>\n",
    "> 1. Merge view_log and item dataset based on item_id\n",
    "\n",
    "> 2. Merge train and test dataset (only columns impression_id, impression_time, user_id) with already merged view_log and item dataset based on user_id\n",
    "\n",
    "> 3. From the merged output dataset in step2, filter rows where server time of the the view log must be less than or equal to ad impression time.\n",
    "\n",
    "> 4. From the filtered dataset in step4, prepare aggregation data for each impression id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3118622 entries, 0 to 3118621\n",
      "Data columns (total 5 columns):\n",
      "server_time    datetime64[ns]\n",
      "device_type    object\n",
      "session_id     int64\n",
      "user_id        int64\n",
      "item_id        int64\n",
      "dtypes: datetime64[ns](1), int64(3), object(1)\n",
      "memory usage: 119.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Converting Impression_time field to datetime format in train and test dataset\n",
    "view['server_time'] = pd.to_datetime(view.server_time)\n",
    "#Anlaysing view_log dataset\n",
    "view.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3116840 entries, 0 to 3116839\n",
      "Data columns (total 14 columns):\n",
      "server_time       datetime64[ns]\n",
      "device_type       object\n",
      "session_id        int64\n",
      "user_id           int64\n",
      "item_id           int64\n",
      "server_weekday    object\n",
      "server_month      int64\n",
      "server_hour       int64\n",
      "server_day        int64\n",
      "item_price        int64\n",
      "category_1        int64\n",
      "category_2        int64\n",
      "category_3        int64\n",
      "product_type      int64\n",
      "dtypes: datetime64[ns](1), int64(11), object(2)\n",
      "memory usage: 356.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Deriving dayoftheweek, month, hour and day from servertime in view_log\n",
    "view['server_weekday'] = view.server_time.dt.weekday_name\n",
    "view['server_month'] = view.server_time.dt.month\n",
    "view['server_hour'] = view.server_time.dt.round('H').dt.hour\n",
    "view['server_day'] = view.server_time.dt.day\n",
    "\n",
    "#Merging view_log and item_data\n",
    "view_item = view.merge(item, on='item_id')\n",
    "view_item.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ts = pd.concat([tr[['impression_id', 'impression_time', 'user_id']],\n",
    "                   ts[['impression_id', 'impression_time', 'user_id']]], axis='rows', sort=False)\n",
    "\n",
    "tr_ts1 = tr_ts.merge(view_item, on='user_id', how='inner')\n",
    "\n",
    "tr_ts2 = tr_ts1[tr_ts1.server_time<=tr_ts1.impression_time].copy()\n",
    "del [[tr_ts, tr_ts1]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new aggregation dataset for every user id based on merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many device types did each user used?\n",
    "#How many unique session_id's for each user in total?\n",
    "#How many items & unique items did each user visit?\n",
    "#What's the minimum, maximum & average price of all the items user visited?\n",
    "#How many unique categories & product types did each user visited?\n",
    "agg_col = {'device_type': ['nunique'], 'session_id':['nunique'], 'item_id': ['nunique', 'count'],\n",
    "           'item_price': ['min', 'max', 'mean'], 'category_1': ['nunique'], 'category_2':['nunique'],\n",
    "           'category_3': ['nunique'], 'product_type': ['nunique']\n",
    "          }\n",
    "\n",
    "imp_agg = tr_ts2.groupby(['impression_id']).agg(agg_col)\n",
    "imp_agg.columns=['imp_' + '_'.join(col).strip() for col in imp_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many visits & unique items in each weekday, month, hour, day, category_1 & category_2?\n",
    "col_l = ['server_weekday', 'server_month', 'server_hour', 'server_day', 'category_1', 'category_2']\n",
    "\n",
    "for c in col_l:\n",
    "    for x in tr_ts2[c].unique():\n",
    "        tmp_map = tr_ts2[(tr_ts2[c]==x)].groupby(['impression_id']).size()\n",
    "        cname1 = 'imp_'+ str(c) + '_' + str(x) +'_item_count'\n",
    "        imp_agg[cname1] = imp_agg.index.map(tmp_map)\n",
    "        imp_agg.loc[imp_agg[cname1].isnull(), cname1] = 0\n",
    "        \n",
    "        tmp_map = tr_ts2[(tr_ts2[c]==x)].groupby(['impression_id'])['item_id'].nunique()\n",
    "        cname2 = 'imp_'+ str(c) + '_' + str(x) +'_item_nunique'\n",
    "        imp_agg[cname2] = imp_agg.index.map(tmp_map)\n",
    "        imp_agg.loc[imp_agg[cname2].isnull(), cname2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping merged dataset tr_ts2\n",
    "del [[tr_ts2]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting aggregation dataset into imp_agg.csv file\n",
    "imp_agg.reset_index().to_csv('imp_agg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
