{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Datasets\n",
    "tr = pd.read_csv('train.csv')\n",
    "ts = pd.read_csv('test.csv')\n",
    "view = pd.read_csv('view_log.csv')\n",
    "item = pd.read_csv('item_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 237609 entries, 0 to 237608\n",
      "Data columns (total 7 columns):\n",
      "impression_id      237609 non-null object\n",
      "impression_time    237609 non-null datetime64[ns]\n",
      "user_id            237609 non-null int64\n",
      "app_code           237609 non-null int64\n",
      "os_version         237609 non-null object\n",
      "is_4G              237609 non-null int64\n",
      "is_click           237609 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(4), object(2)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Converting Impression_time field to datetime format in train and test dataset\n",
    "tr['impression_time'] = pd.to_datetime(tr.impression_time)\n",
    "ts['impression_time'] = pd.to_datetime(ts.impression_time)\n",
    "tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Objective:</font>\n",
    "> For every unique userid in view_log dataset get the entire log data aggregation based on user_id.\n",
    "\n",
    "### <font color='green'>Approach:</font>\n",
    "> 1. Merge view_log and item dataset\n",
    "\n",
    "> 2. Prepare user level aggregation data from the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3116840 entries, 0 to 3116839\n",
      "Data columns (total 14 columns):\n",
      "server_time       datetime64[ns]\n",
      "device_type       object\n",
      "session_id        int64\n",
      "user_id           int64\n",
      "item_id           int64\n",
      "server_weekday    object\n",
      "server_month      int64\n",
      "server_hour       int64\n",
      "server_day        int64\n",
      "item_price        int64\n",
      "category_1        int64\n",
      "category_2        int64\n",
      "category_3        int64\n",
      "product_type      int64\n",
      "dtypes: datetime64[ns](1), int64(11), object(2)\n",
      "memory usage: 356.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Converting Impression_time field to datetime format in train and test dataset\n",
    "view['server_time'] = pd.to_datetime(view.server_time)\n",
    "#Anlaysing view_log dataset\n",
    "\n",
    "#Deriving dayoftheweek, month, hour and day from servertime in view_log\n",
    "view['server_weekday'] = view.server_time.dt.weekday_name\n",
    "view['server_month'] = view.server_time.dt.month\n",
    "view['server_hour'] = view.server_time.dt.round('H').dt.hour\n",
    "view['server_day'] = view.server_time.dt.day\n",
    "\n",
    "#Merging view_log and item_data\n",
    "view_item = view.merge(item, on='item_id')\n",
    "view_item.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new aggregation dataset for every user id based on merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many device types did each user used?\n",
    "#How many unique session_id's for each user in total?\n",
    "#How many items & unique items did each user visit?\n",
    "#What's the minimum, maximum & average price of all the items user visited?\n",
    "#How many unique categories & product types did each user visited?\n",
    "agg_col = {'device_type': ['nunique'], 'session_id':['nunique'], 'item_id': ['nunique', 'count'],\n",
    "           'item_price': ['min', 'max', 'mean'], 'category_1': ['nunique'], 'category_2':['nunique'],\n",
    "           'category_3': ['nunique'], 'product_type': ['nunique']\n",
    "          }\n",
    "\n",
    "user_agg = view_item.groupby(['user_id']).agg(agg_col)\n",
    "user_agg.columns=['user_' + '_'.join(col).strip() for col in user_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many visits & unique items in each weekday, month, hour, day, category_1 & category_2?\n",
    "col_l = ['server_weekday', 'server_month', 'server_hour', 'server_day', 'category_1', 'category_2']\n",
    "\n",
    "for c in col_l:\n",
    "    for x in view_item[c].unique():\n",
    "        tmp_map = view_item[(view_item[c]==x)].groupby(['user_id']).size()\n",
    "        cname1 = 'user_'+ str(c) + '_' + str(x) +'_item_count'\n",
    "        user_agg[cname1] = user_agg.index.map(tmp_map)\n",
    "        user_agg.loc[user_agg[cname1].isnull(), cname1] = 0\n",
    "        \n",
    "        tmp_map = view_item[(view_item[c]==x)].groupby(['user_id'])['item_id'].nunique()\n",
    "        cname2 = 'user_'+ str(c) + '_' + str(x) +'_item_nunique'\n",
    "        user_agg[cname2] = user_agg.index.map(tmp_map)\n",
    "        user_agg.loc[user_agg[cname2].isnull(), cname2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting aggregation dataset into user_agg.csv file\n",
    "user_agg.reset_index().to_csv('user_agg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
